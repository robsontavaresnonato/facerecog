{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\"\"\" handling files support packages \"\"\"\n",
    "from glob import glob\n",
    "\n",
    "\"\"\" logic support packages \"\"\"\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\"\"\" plot support packages \"\"\"\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from IPython.display import Image\n",
    "#import pydotplus\n",
    "\n",
    "\"\"\" image trasformation packages \"\"\"\n",
    "from PIL import Image\n",
    "import skimage.io as skio\n",
    "\n",
    "\"\"\" statistical data visualization packages\"\"\"\n",
    "import seaborn as sns\n",
    "\n",
    "\"\"\" machine learning functions \"\"\"\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\"\"\" seaborn configurations \"\"\"\n",
    "sns.set_style('white')\n",
    "sns.set_context('talk')\n",
    "plt.rcParams['figure.figsize'] = 20, 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from funcoes import extract_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tentativa de com base equilibrada p%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "combinacoes_equilibradas = pd.read_csv(\"../combinacoes\"+str(p)+\".txt\", header = 0, sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X = combinacoes_equilibradas[[\"mse\", \"iss\", \"mse_centro\", \"iss_centro\",\n",
    "            \"mse_canny\", \"iss_canny\", \"mse_canny_centro\", \"iss_canny_centro\",\n",
    "            \"mse_skeleton\", \"iss_skeleton\", \"mse_skeleton_centro\", \"iss_skeleton_centro\",\n",
    "            \"imgA_mean\", \"imgB_mean\", \"imgA_var\", \"imgB_var\",\n",
    "            #imgA_contraste, imgB_contraste,\n",
    "            #imgA_angular_momentum, imgB_angular_momentum,\n",
    "            \"imgA_entropy\", \"imgB_entropy\"]]\n",
    "\n",
    "y = combinacoes_equilibradas[\"resposta\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#from sklearn.manifold import Isomap\n",
    "#iso = Isomap(n_components = 2)\n",
    "#data_projected = iso.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#data_projected.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#plt.scatter(data_projected[:, 0], data_projected[:, 1], c=y,\n",
    "#            edgecolor='none', alpha=0.5, cmap=plt.cm.get_cmap('nipy_spectral'))\n",
    "#plt.colorbar(label='digita label', ticks=range(10))\n",
    "#plt.clim(-0.5, 9.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.6938461538461539\n",
      "CPU times: user 8 ms, sys: 0 ns, total: 8 ms\n",
      "Wall time: 5.62 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "clf_C = GaussianNB()\n",
    "\n",
    "clf_C.fit(X_train, y_train)\n",
    "\n",
    "print( \"Score: {0}\".format(clf_C.score(X_test, y_test)) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.7557264957264958\n",
      "Best parameters: {'criterion': 'entropy', 'min_samples_split': 40, 'min_samples_leaf': 7}\n",
      "CPU times: user 11.6 s, sys: 4 ms, total: 11.6 s\n",
      "Wall time: 11.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn import tree\n",
    "\n",
    "DTparams = { 'criterion' : ('gini', 'entropy'),\n",
    "           'min_samples_split' : (2, 10, 40),\n",
    "           'min_samples_leaf' : (1, 3, 7, 40)}\n",
    "\n",
    "svr = tree.DecisionTreeClassifier()\n",
    "clf1 = GridSearchCV(svr, DTparams) #criterion = \"gini\", min_samples_split = 80, min_samples_leaf = 3\n",
    "\n",
    "clf1.fit( X = X_train, y = y_train )\n",
    "print( \"Score: {0}\".format(clf1.score(X_test, y_test)) )\n",
    "print( \"Best parameters: \" + str(clf1.best_params_) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clfRF_balanced = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.8029059829059829\n",
      "Best parameters: {'criterion': 'entropy', 'min_samples_split': 10, 'n_estimators': 10, 'min_samples_leaf': 1}\n",
      "CPU times: user 48.5 s, sys: 16 ms, total: 48.5 s\n",
      "Wall time: 48.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "RFparams = {'n_estimators' : (10, 2, 3, 5, 7),\n",
    "           'criterion' : ('gini', 'entropy'),\n",
    "           'min_samples_split' : (2, 10, 40),\n",
    "           'min_samples_leaf' : (1, 5, 10, 40)}\n",
    "\n",
    "svr = RandomForestClassifier()\n",
    "clfRF_balanced = GridSearchCV(svr, RFparams)\n",
    "clfRF_balanced.fit( X = X_train, y = y_train )\n",
    "print( \"Score: {0}\".format(clfRF_balanced.score(X_test, y_test)) )\n",
    "print( \"Best parameters: \" + str(clfRF_balanced.best_params_) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.795042735042735\n",
      "CPU times: user 484 ms, sys: 0 ns, total: 484 ms\n",
      "Wall time: 483 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clfRF_balanced = RandomForestClassifier(criterion = 'entropy', n_estimators=10, min_samples_leaf=5,\n",
    "                                       min_samples_split=10)\n",
    "clfRF_balanced.fit( X = X_train, y = y_train )\n",
    "print( \"Score: {0}\".format(clfRF_balanced.score(X_test, y_test)) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.7507692307692307\n",
      "Best parameters: {'solver': 'newton-cg'}\n",
      "CPU times: user 6.44 s, sys: 8.62 s, total: 15.1 s\n",
      "Wall time: 4.13 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "LRparams = {'solver' : ('newton-cg', 'lbfgs', 'liblinear', 'sag')}\n",
    "\n",
    "svr = LogisticRegression()\n",
    "clfLR = GridSearchCV(svr, LRparams)\n",
    "clfLR.fit( X = X_train, y = y_train )\n",
    "print( \"Score: {0}\".format(clfLR.score(X_test, y_test)) )\n",
    "print( \"Best parameters: \" + str(clfLR.best_params_) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-layer Perceptron classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.7056410256410256\n",
      "Best parameters: <bound method BaseEstimator.get_params of MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
      "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
      "       verbose=False, warm_start=False)>\n",
      "CPU times: user 544 ms, sys: 604 ms, total: 1.15 s\n",
      "Wall time: 289 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "MLPparams = {'hidden_layer_sizes':(100, 20, 50),\n",
    "            'activation' : ('identity', 'logistic', 'tanh', 'relu'),\n",
    "            'solver' : ('lbfgs', 'sgd', 'adam')}\n",
    "\n",
    "svr = MLPClassifier()\n",
    "clfMLP = GridSearchCV(svr, MLPparams)\n",
    "clfMLP = MLPClassifier()\n",
    "clfMLP.fit( X = X_train, y = y_train )\n",
    "print( \"Score: {0}\".format(clfMLP.score(X_test, y_test)) )\n",
    "print( \"Best parameters: \" + str(clfMLP.get_params) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tentativa com base de p = 50%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "combinacoes_equilibradas = pd.read_csv(\"../combinacoes\"+str(p)+\".txt\", header = 0, sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X = combinacoes_equilibradas[[\"mse\", \"iss\", \"mse_centro\", \"iss_centro\",\n",
    "            \"mse_canny\", \"iss_canny\", \"mse_canny_centro\", \"iss_canny_centro\",\n",
    "            \"mse_skeleton\", \"iss_skeleton\", \"mse_skeleton_centro\", \"iss_skeleton_centro\",\n",
    "            \"imgA_mean\", \"imgB_mean\", \"imgA_var\", \"imgB_var\",\n",
    "            #imgA_contraste, imgB_contraste,\n",
    "            #imgA_angular_momentum, imgB_angular_momentum,\n",
    "            \"imgA_entropy\", \"imgB_entropy\"]]\n",
    "\n",
    "y = combinacoes_equilibradas[\"resposta\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.5988603988603989\n",
      "CPU times: user 0 ns, sys: 8 ms, total: 8 ms\n",
      "Wall time: 2.92 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "clf_C = GaussianNB()\n",
    "\n",
    "clf_C.fit(X_train, y_train)\n",
    "\n",
    "print( \"Score: {0}\".format(clf_C.score(X_test, y_test)) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.7170940170940171\n",
      "Best parameters: {'criterion': 'gini', 'min_samples_split': 40, 'min_samples_leaf': 3}\n",
      "CPU times: user 6.02 s, sys: 4 ms, total: 6.02 s\n",
      "Wall time: 6.02 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn import tree\n",
    "\n",
    "DTparams = { 'criterion' : ('gini', 'entropy'),\n",
    "           'min_samples_split' : (2, 10, 40),\n",
    "           'min_samples_leaf' : (1, 3, 7, 40)}\n",
    "\n",
    "svr = tree.DecisionTreeClassifier()\n",
    "clf1 = GridSearchCV(svr, DTparams) #criterion = \"gini\", min_samples_split = 80, min_samples_leaf = 3\n",
    "\n",
    "clf1.fit( X = X_train, y = y_train )\n",
    "print( \"Score: {0}\".format(clf1.score(X_test, y_test)) )\n",
    "print( \"Best parameters: \" + str(clf1.best_params_) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clfRF_balanced = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.7336182336182336\n",
      "Best parameters: {'criterion': 'gini', 'min_samples_split': 10, 'n_estimators': 10, 'min_samples_leaf': 5}\n",
      "CPU times: user 25.4 s, sys: 28 ms, total: 25.4 s\n",
      "Wall time: 25.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "RFparams = {'n_estimators' : (10, 2, 3, 5, 7),\n",
    "           'criterion' : ('gini', 'entropy'),\n",
    "           'min_samples_split' : (2, 10, 40),\n",
    "           'min_samples_leaf' : (1, 5, 10, 40)}\n",
    "\n",
    "svr = RandomForestClassifier()\n",
    "clfRF_balanced = GridSearchCV(svr, RFparams)\n",
    "clfRF_balanced.fit( X = X_train, y = y_train )\n",
    "print( \"Score: {0}\".format(clfRF_balanced.score(X_test, y_test)) )\n",
    "print( \"Best parameters: \" + str(clfRF_balanced.best_params_) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.6373219373219373\n",
      "Best parameters: {'solver': 'newton-cg'}\n",
      "CPU times: user 3.18 s, sys: 4.38 s, total: 7.56 s\n",
      "Wall time: 2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "LRparams = {'solver' : ('newton-cg', 'lbfgs', 'liblinear', 'sag')}\n",
    "\n",
    "svr = LogisticRegression()\n",
    "clfLR = GridSearchCV(svr, LRparams)\n",
    "clfLR.fit( X = X_train, y = y_train )\n",
    "print( \"Score: {0}\".format(clfLR.score(X_test, y_test)) )\n",
    "print( \"Best parameters: \" + str(clfLR.best_params_) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-layer Perceptron classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.49202279202279203\n",
      "Best parameters: <bound method BaseEstimator.get_params of MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
      "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
      "       verbose=False, warm_start=False)>\n",
      "CPU times: user 200 ms, sys: 148 ms, total: 348 ms\n",
      "Wall time: 86.8 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "MLPparams = {'hidden_layer_sizes':(100, 20, 50),\n",
    "            'activation' : ('identity', 'logistic', 'tanh', 'relu'),\n",
    "            'solver' : ('lbfgs', 'sgd', 'adam')}\n",
    "\n",
    "svr = MLPClassifier()\n",
    "clfMLP = GridSearchCV(svr, MLPparams)\n",
    "clfMLP = MLPClassifier()\n",
    "clfMLP.fit( X = X_train, y = y_train )\n",
    "print( \"Score: {0}\".format(clfMLP.score(X_test, y_test)) )\n",
    "print( \"Best parameters: \" + str(clfMLP.get_params) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binarizando o melhor modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#imgA = skio.imread(\"../letras/caracter1.png\")\n",
    "#imgB = skio.imread(\"../letras/caracter15.png\")\n",
    "\n",
    "#mse, iss, mse_centro, iss_centro,\\\n",
    "#\t\t\tmse_canny, iss_canny, mse_canny_centro, iss_canny_centro,\\\n",
    "#\t\t\tmse_skeleton, iss_skeleton, mse_skeleton_centro, iss_skeleton_centro = extract_stats(imgA, imgB)\n",
    "        \n",
    "#print(clfRF_balanced.predict( [[mse, iss, mse_centro, iss_centro,\n",
    "#\t\t\tmse_canny, iss_canny, mse_canny_centro, iss_canny_centro,\n",
    "#\t\t\tmse_skeleton, iss_skeleton, mse_skeleton_centro, iss_skeleton_centro]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#joblib.dump(clfRF_balanced, 'classifier_balanced.pkl') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
