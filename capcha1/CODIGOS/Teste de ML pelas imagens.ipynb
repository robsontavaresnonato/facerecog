{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\"\"\" handling files support packages \"\"\"\n",
    "from glob import glob\n",
    "\n",
    "\"\"\" logic support packages \"\"\"\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\"\"\" plot support packages \"\"\"\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from IPython.display import Image\n",
    "#import pydotplus\n",
    "\n",
    "\"\"\" image trasformation packages \"\"\"\n",
    "from PIL import Image\n",
    "import skimage.io as skio\n",
    "\n",
    "\"\"\" statistical data visualization packages\"\"\"\n",
    "import seaborn as sns\n",
    "\n",
    "\"\"\" machine learning functions \"\"\"\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\"\"\" seaborn configurations \"\"\"\n",
    "sns.set_style('white')\n",
    "sns.set_context('talk')\n",
    "plt.rcParams['figure.figsize'] = 20, 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#from funcoes import ler_letras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#letras, letters_dict = ler_letras(\"../letras.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['path', 'rotulo', 'caixa_alta_baixa']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"../letras.csv\", header = 0, sep=\",\")\n",
    "list(data.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temos 35 classes: ['1', '2', '3', '4', '5', '6', '7', '8', '9', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n"
     ]
    }
   ],
   "source": [
    "print(\"Temos {0} classes: {1}\".format(len(list(set(data.rotulo))), sorted(list(set(data.rotulo)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img_pixels = Image.open(data['path'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#for i, file in enumerate(list(data['path'])):\n",
    "    #print(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = []\n",
    "y = []\n",
    "\n",
    "for i, file in enumerate(list(data['path'])):\n",
    "    label = data['rotulo'][i]\n",
    "    img_pixels = list(Image.open(file).getdata())\n",
    "    X.append(img_pixels)\n",
    "    y.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#from sklearn import preprocessing\n",
    "\n",
    "#le = preprocessing.LabelEncoder()\n",
    "#le.fit(y)\n",
    "#ley = le.transform(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unsupervised Learnind: Dimensionality Reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "temos 1140 imagens cada uma com 1750 dimensoes\n"
     ]
    }
   ],
   "source": [
    "print(\"temos {0} imagens cada uma com {1} dimensoes\".format(len(X), len(X[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "estimator = decomposition.FastICA(#n_components=n_components,\n",
    "                                  whiten=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FastICA(algorithm='parallel', fun='logcosh', fun_args=None, max_iter=200,\n",
       "    n_components=None, random_state=None, tol=0.0001, w_init=None,\n",
       "    whiten=True)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = estimator.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "temos 1140 imagens cada uma com 1140 dimensoes\n"
     ]
    }
   ],
   "source": [
    "print(\"temos {0} imagens cada uma com {1} dimensoes\".format(len(data), len(data[0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A base relativa aos pixels esta muito confusa, as classes estao muito misturadas para os features (imagens)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Divisao da base em treino e teste e aplicacao de algoritmos de aprendizado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.04678362573099415\n",
      "Best parameters: <bound method BaseEstimator.get_params of MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
      "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
      "       verbose=False, warm_start=False)>\n",
      "CPU times: user 1min 8s, sys: 1min 3s, total: 2min 11s\n",
      "Wall time: 41 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ricardo/envs/facerecog/lib/python3.5/site-packages/sklearn/neural_network/multilayer_perceptron.py:563: ConvergenceWarning: Stochastic Optimizer: Maximum iterations reached and the optimization hasn't converged yet.\n",
      "  % (), ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "MLPparams = {'hidden_layer_sizes':(100, 20, 50),\n",
    "             'activation' : ('identity', 'logistic', 'tanh', 'relu'),\n",
    "             'solver' : ('lbfgs', 'sgd', 'adam'),\n",
    "             'learning_rate': ('constant', 'invscaling', 'adaptative')\n",
    "            }\n",
    "\n",
    "svr = MLPClassifier(max_iter = 200000)\n",
    "clfMLP = GridSearchCV(svr, MLPparams)\n",
    "clfMLP = MLPClassifier()\n",
    "clfMLP.fit( X = X_train, y = y_train )\n",
    "print( \"Score: {0}\".format(clfMLP.score(X_test, y_test)) )\n",
    "print( \"Best parameters: \" + str(clfMLP.get_params) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.043859649122807015\n",
      "Best parameters: {'min_samples_leaf': 1, 'n_estimators': 500, 'min_samples_split': 2, 'criterion': 'entropy'}\n",
      "CPU times: user 3h 22min 10s, sys: 38.5 s, total: 3h 22min 48s\n",
      "Wall time: 3h 22min 59s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clfRF_balanced = RandomForestClassifier()\n",
    "\n",
    "\n",
    "RFparams = {'n_estimators' : (1000, 500, 200, 100),\n",
    "           'criterion' : ('gini', 'entropy'),\n",
    "           'min_samples_split' : (2, 10, 40),\n",
    "           'min_samples_leaf' : (1, 5, 10, 40)}\n",
    "\n",
    "svr = RandomForestClassifier()\n",
    "clfRF_balanced = GridSearchCV(svr, RFparams)\n",
    "clfRF_balanced.fit( X = X_train, y = y_train )\n",
    "print( \"Score: {0}\".format(clfRF_balanced.score(X_test, y_test)) )\n",
    "print( \"Best parameters: \" + str(clfRF_balanced.best_params_) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.017543859649122806\n",
      "Best parameters: {'C': 1, 'kernel': 'poly', 'degree': 2}\n",
      "CPU times: user 55.1 s, sys: 76 ms, total: 55.1 s\n",
      "Wall time: 55.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.svm import SVC\n",
    "clf = SVC() # kernel = 'poly', degree = 2, max_iter = 100000\n",
    "\n",
    "SVMparams = [#{'kernel': ['rbf'], 'gamma': [1e-3, 1e-4],\n",
    "             #        'C': [1, 10, 100, 1000]},\n",
    "            #{'kernel': ['linear'], 'C': [1, 10, 100, 1000]},\n",
    "            {'kernel' : ['poly'], 'degree': [1, 2, 3],\n",
    "                     'C': [1, 10, 100, 1000]}]\n",
    "\n",
    "svr = SVC()\n",
    "clf = GridSearchCV(svr, SVMparams)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "print( \"Score: {0}\".format(clf.score(X_test, y_test)) )\n",
    "print( \"Best parameters: \" + str(clf.best_params_) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import tensorflow as tf\n",
    "\n",
    "#image_size = 35 * 50\n",
    "#n_classes = len(list(set(data.rotulo)))\n",
    "#x = tf.placeholder(tf.float32, [None, image_size])\n",
    "#W = tf.Variable(tf.zeros([image_size, n_classes]))\n",
    "#b = tf.Variable(tf.zeros([n_classes]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#imgs = skio.imread_collection(list(data['path']))\n",
    "#imgA = crop_char(imgs[0], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#print(clf.predict([item for sublist in imgA.tolist() for item in sublist]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "if save:\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    clf = RandomForestClassifier(n_estimators = 500, criterion = 'entropy',\n",
    "                                  min_samples_split = 2, min_samples_leaf= 1)\n",
    "\n",
    "    clf.fit(X_train, y_train)\n",
    "    print( \"Score: {0}\".format(clf.score(X_test, y_test)) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if save: joblib.dump(clf, 'classifier_image.pkl') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
